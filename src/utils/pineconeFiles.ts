import { OpenAIEmbeddings } from 'langchain/embeddings/openai';
import { PDFLoader } from 'langchain/document_loaders/fs/pdf';
import { getPineconeIndex } from './pineconeClient';
import { PineconeStore } from 'langchain/vectorstores/pinecone';
import { PineconeClient } from '@pinecone-database/pinecone';
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';

const DOCS_MAX_LENGTH = 150;

export const langchainPineconeUpsert = async (filePath: string, pineconeClient: PineconeClient, fileName: string) => {
  // use pdfjs to load pdf
  // https://js.langchain.com/docs/modules/indexes/document_loaders/examples/file_loaders/pdf
  const loader = new PDFLoader(filePath, {
    pdfjs: () => import('pdfjs-dist/legacy/build/pdf.js'),
    splitPages: false,
  });

  const pdf = await loader.load();
  // const content = pdf[0].pageContent;
  // const metadata = pdf[0].metadata;

  // list collections - we'll use the first one which is the default for this example
  const pineconeIndex = await getPineconeIndex(pineconeClient);

  /* Split text into chunks */
  const textSplitter = new RecursiveCharacterTextSplitter({
    chunkSize: 1000,
    chunkOverlap: 200,
  });

  const docs = await textSplitter.splitDocuments(pdf);

  // todo: add threshold for big documents
  if (docs.length > DOCS_MAX_LENGTH) {
    throw new Error('Please upload a smaller document');
  }

  // add documents to index
  await PineconeStore.fromDocuments(docs, new OpenAIEmbeddings(), {
    pineconeIndex,
    // todo make the namespace dynamic so we can store one namespace per pdf in pinecone
    namespace: fileName,
  });

  return pdf;
};
